{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1=[4.999130774913988,24.99130774914093]\n",
      "\n",
      "x2=[4.999130774913811,24.991307749140223]\n",
      "\n",
      "x3=[4.999130774913635,24.991307749139516]\n",
      "\n",
      "\n",
      "f(x*)=15.993046954861327\n"
     ]
    }
   ],
   "source": [
    "# problem 6 \n",
    "#Newton method \n",
    "# define the augmented lagrangian and its gradient \n",
    "function obj(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    obj= (1-x1)^2+ la * (x2-x1^2)+ c/2 * (x2-x1^2)^2;\n",
    "    return obj\n",
    "end\n",
    "function grd_x(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    grd_x= [-2(1-x1)*x1 - 2* la *x1-2*c*x1*(x2-x1^2), la+c*(x2-x1^2)];\n",
    "    return grd_x\n",
    "end\n",
    "function hes_x(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    hes_x= [-2+4*x1-2*la+6*c*x1^2-2c*x2 -2*c*x1; -2*c*x1 c];\n",
    "    return hes_x\n",
    "end\n",
    "\n",
    "\n",
    "function newtmin( obj,grd_x,hes_x, x0,c,la,optTol,alpha,beta; maxit=200)\n",
    "    # Minimize a function the augemented Lagrangian using Newton’s method.\n",
    "    # stop criteria = |grad|< optTol\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    f_0 = obj(x0,la,c);\n",
    "    grad_0 = grd_x(x0,la,c);\n",
    "    Hes_0 = hes_x(x0,la,c);\n",
    "    Hes_0 = Hes_0-min(eigmin(Hes_0)-1e-2,0)*eye(length(x0));\n",
    "        \n",
    "    x = x0;\n",
    "    f_x = f_0;\n",
    "    grad_x = grad_0;   \n",
    "    Hes_x = Hes_0;\n",
    "    \n",
    "    #Counts the iteratives.\n",
    "    int = 0;\n",
    "    \n",
    "    while optTol  <= norm(grad_x,2)\n",
    "        \n",
    "        int=int+1;\n",
    "        # if the iteratives number is greater than maxit, break down.\n",
    "        if int >= maxit\n",
    "            break\n",
    "        end\n",
    "        \n",
    "    # applying netwon method\n",
    "    \n",
    "    # determine the direction.\n",
    "    \n",
    "        dx = - inv(Hes_x) *  grad_x ;\n",
    "    \n",
    "        t=1;\n",
    "        bt=0;\n",
    "        at=grad_x' * dx;\n",
    "\n",
    "        while obj(x+t*dx,la,c) >= obj(x,la,c)+alpha*t*at[1]\n",
    "        \n",
    "                t= t * beta;\n",
    "            end # back tracking\n",
    "        \n",
    "        \n",
    "        x=x+dx*t;\n",
    "    \n",
    "        f_x=obj(x,la,c);\n",
    "        grad_x = grd_x(x,la,c);\n",
    "        Hes_x = hes_x(x,la,c);\n",
    "        Hes_x = Hes_x - min(eigmin(Hes_x)-1e-3,0)*eye(length(x0));\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    end # while newton M\n",
    "    \n",
    "    return(x, int) \n",
    "    \n",
    "end   # function\n",
    "\n",
    "\n",
    "beta = 0.5;\n",
    "alpha=0.3;\n",
    "x0=[5,2];\n",
    "c=1000;\n",
    "lambda=0;\n",
    "opt=1e-3;\n",
    "X=[];\n",
    "x_t=0;\n",
    "count=0;\n",
    "while opt >= 1e-5\n",
    "    #newtmin( obj,grd_x,hes_x, x0,c,lambda,optTol,alpha,beta; maxit=200)\n",
    "    (x, int)= newtmin(obj,grd_x,hes_x,x0,c,lambda,opt ,alpha,beta);\n",
    "    X=push!(X,x);\n",
    "    x0=x;\n",
    "    c=4*c;\n",
    "    opt=opt*0.1;\n",
    "    x_t=x;\n",
    "    count=count+1;\n",
    "    println(\"x\",count,\"=\",x,\"\\n\")\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f_min=obj(x_t,0,0);\n",
    "println(\"\\n\",\"f(x*)=\",f_min )\n",
    "############### HW5 ##########\n",
    "############### HW5 ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1=[0.9800047284468982,0.40885185338330793]\n",
      "\n",
      "x2=[0.9933007878407796,0.2506466849005941]\n",
      "\n",
      "x3=[0.9977257398904598,0.16615944300811278]\n",
      "\n",
      "x4=[0.9995461760702379,0.11424056970344519]\n",
      "\n",
      "x5=[1.000358291627118,0.08088871109725551]\n",
      "\n",
      "x6=[0.9983084901451965,0.11659742737486589]\n",
      "\n",
      "x7=[0.9981322022809669,0.12248149722525056]\n",
      "\n",
      "x8=[0.9984550517999409,0.11147232543320534]\n",
      "\n",
      "x9=[0.9987487472199303,0.10040918373275508]\n",
      "\n",
      "\n",
      "f(x*)=0.5914867443739277\n"
     ]
    }
   ],
   "source": [
    "# problem 7\n",
    "#NEWTON METHOD\n",
    "# define the augmented lagrangian and its gradient \n",
    "function obj(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    obj= log(1+x1^2)-x2+la*((1+x1^2)^2+x2^2-4)+c/2 * ((1+x1^2)^2+x2^2-4)^2;\n",
    "    return obj\n",
    "end\n",
    "function grd_x(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    grd_x= [2*x1/(1+x1^2) + 4*la*(1+x1^2)*x1+4*c*x1*(1+x1^2)*((1+x1^2)^2+x2^2-4), -1+2*la*x2+2*x2*c*((1+x1^2)^2+x2^2-4)];\n",
    "    return grd_x\n",
    "end\n",
    "function hes_x(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    hes_x= [(2-2*x1^2)/((1+x1^2)^2)+4*la+12*la*x1^2+4*c*(1+3*x1^2)*(x2^2-4+(x1^2+1)^2)+16*c*(x1+x1^3)^2  8*c*x2*x1*(1+x1^2);8*c*x1*x2*(1+x1^2) 2*la+2*c*((1+x1^2)^2+x2^2-4)];\n",
    "    return hes_x\n",
    "end\n",
    "\n",
    "\n",
    "function newtmin( obj,grd_x,hes_x, x0,c,la,optTol,alpha,beta; maxit=200)\n",
    "    # Minimize a function the augemented Lagrangian using Newton’s method.\n",
    "    # stop criteria = |grad|< optTol\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    f_0 = obj(x0,la,c);\n",
    "    grad_0 = grd_x(x0,la,c);\n",
    "    Hes_0 = hes_x(x0,la,c);\n",
    "    Hes_0 = Hes_0-min(eigmin(Hes_0)-1e-4,0)*eye(length(x0));\n",
    "        \n",
    "    x = x0;\n",
    "    f_x = f_0;\n",
    "    grad_x = grad_0;   \n",
    "    Hes_x = Hes_0;\n",
    "    \n",
    "    #Counts the iteratives.\n",
    "    int = 0;\n",
    "    \n",
    "    while optTol  <= norm(grad_x,2)\n",
    "        \n",
    "        int=int+1;\n",
    "        # if the iteratives number is greater than maxit, break down.\n",
    "        if int >= maxit\n",
    "            break\n",
    "        end\n",
    "        \n",
    "    # applying netwon method\n",
    "    \n",
    "    # determine the direction.\n",
    "    \n",
    "        dx = - inv(Hes_x) *  grad_x ;\n",
    "    \n",
    "        t=1;\n",
    "        bt=0;\n",
    "        at=grad_x' * dx;\n",
    "\n",
    "        while obj(x+t*dx,la,c) >= obj(x,la,c)+alpha*t*at[1]\n",
    "        \n",
    "                t= t * beta;\n",
    "            end # back tracking\n",
    "        \n",
    "        \n",
    "        x=x+dx*t;\n",
    "    \n",
    "        f_x=obj(x,la,c);\n",
    "        grad_x = grd_x(x,la,c);\n",
    "        Hes_x = hes_x(x,la,c);\n",
    "        Hes_x = Hes_x - min(eigmin(Hes_x)-1e-3,0)*eye(length(x0));\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    end # while newton M\n",
    "    \n",
    "    return(x, int) \n",
    "    \n",
    "end   # function\n",
    "\n",
    "\n",
    "beta = 0.5;\n",
    "alpha=0.3;\n",
    "x0=[2,1];\n",
    "c=10000;\n",
    "lambda=0;\n",
    "opt=1e-1;\n",
    "X=[];\n",
    "x_t=0;\n",
    "count=0;\n",
    "while opt >= 1e-7\n",
    "    (x, int)= newtmin(obj,grd_x,hes_x,x0,c,lambda,opt ,alpha,beta);\n",
    "    X=push!(X,x);\n",
    "    x0=x;\n",
    "    c=4*c;\n",
    "    opt=opt*0.2;\n",
    "    x_t=x;\n",
    "    count=count+1;\n",
    "    println(\"x\",count,\"=\",x,\"\\n\")\n",
    "end\n",
    "f_min=obj(x_t,0,0);\n",
    "println(\"\\n\",\"f(x*)=\",f_min )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1=[1.955956398260315,4.6013296349099395]\n",
      "\n",
      "x2=[1.9558999839144497,4.601462292191275]\n",
      "\n",
      "x3=[1.9558717910971313,4.601528608541834]\n",
      "\n",
      "\n",
      "f(x*)=-1.0\n"
     ]
    }
   ],
   "source": [
    "# problem 8\n",
    "# NEWTON METHOD\n",
    "# define the augmented lagrangian and its gradient \n",
    "function obj(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    la1=la[1];\n",
    "    la2=la[2];\n",
    "    \n",
    "    obj= -1 + la1*(x1^2+x2^2-25)+la2*(x1*x2-9)+c/2 * ((x1^2+x2^2-25)^2+(x1*x2-9)^2);\n",
    "    return obj\n",
    "end\n",
    "function grd_x(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    la1=la[1];\n",
    "    la2=la[2];\n",
    "    grd_x= [2*la1*x1+la2*x2+2*c*x1*(x1^2+x2^2-25)+c*x2*(x1*x2-9), 2*la1*x2+la2*x1+2*c*x2*(x1^2+x2^2-25)+c*x1*(x1*x2-9)];\n",
    "    return grd_x\n",
    "end\n",
    "function hes_x(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    la1=la[1];\n",
    "    la2=la[2];\n",
    "    hes_x= [2*la1+6*c*x1^2+c*x2^2 la2+6*c*x1*x2;la2+6*c*x1*x2 2*la1+6*c*x2^2+c*x1^2 ];\n",
    "    return hes_x\n",
    "end\n",
    "\n",
    "\n",
    "function newtmin( obj,grd_x,hes_x, x0,c,la,optTol,alpha,beta; maxit=200)\n",
    "    # Minimize a function the augemented Lagrangian using Newton’s method.\n",
    "    # stop criteria = |grad|< optTol\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    f_0 = obj(x0,la,c);\n",
    "    grad_0 = grd_x(x0,la,c);\n",
    "    Hes_0 = hes_x(x0,la,c);\n",
    "    Hes_0 = Hes_0-min(eigmin(Hes_0)-1e-4,0)*eye(length(x0));\n",
    "        \n",
    "    x = x0;\n",
    "    f_x = f_0;\n",
    "    grad_x = grad_0;   \n",
    "    Hes_x = Hes_0;\n",
    "    \n",
    "    #Counts the iteratives.\n",
    "    int = 0;\n",
    "    \n",
    "    while optTol  <= norm(grad_x,2)\n",
    "        \n",
    "        int=int+1;\n",
    "        # if the iteratives number is greater than maxit, break down.\n",
    "        if int >= maxit\n",
    "            break\n",
    "        end\n",
    "        \n",
    "    # applying netwon method\n",
    "    \n",
    "    # determine the direction.\n",
    "    \n",
    "        dx = - inv(Hes_x) *  grad_x ;\n",
    "    \n",
    "        t=1;\n",
    "        bt=0;\n",
    "        at=grad_x' * dx;\n",
    "\n",
    "        while obj(x+t*dx,la,c) >= obj(x,la,c)+alpha*t*at[1]\n",
    "        \n",
    "                t= t * beta;\n",
    "            end # back tracking\n",
    "        \n",
    "        \n",
    "        x=x+dx*t;\n",
    "    \n",
    "        f_x=obj(x,la,c);\n",
    "        grad_x = grd_x(x,la,c);\n",
    "        Hes_x = hes_x(x,la,c);\n",
    "        Hes_x = Hes_x - min(eigmin(Hes_x)-1e-3,0)*eye(length(x0));\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    end # while newton M\n",
    "    \n",
    "    return(x, int) \n",
    "    \n",
    "end   # function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "beta = 0.1;\n",
    "alpha=0.4;\n",
    "\n",
    "x0=[1.2,2.1];\n",
    "c=500;\n",
    "lambda=[1,0];\n",
    "opt=1e-3;\n",
    "X=[];\n",
    "x_t=0;\n",
    "count=0;\n",
    "while opt >= 1e-5\n",
    "\n",
    "    (x, int)= newtmin(obj,grd_x,hes_x,x0,c,lambda,opt ,alpha,beta);\n",
    "    X=push!(X,x);\n",
    "    x0=x;\n",
    "    c=2*c;\n",
    "    opt=opt*0.2;\n",
    "    x_t=x;\n",
    "    count=count+1;\n",
    "    println(\"x\",count,\"=\",x,\"\\n\")\n",
    "end\n",
    "f_min=obj(x_t,[0,0],0);\n",
    "println(\"\\n\",\"f(x*)=\",f_min )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x45=[-722.9995530770341,-963.9993822808964]\n",
      "\n",
      "x46=[-723.0004631819141,-964.0006066701999]\n",
      "\n",
      "x47=[-723.0000019913492,-963.9999972009782]\n",
      "\n",
      "x48=[-723.0000020992675,-964.000000071948]\n",
      "\n",
      "x49=[-722.9999999460385,-963.9999985645125]\n",
      "\n",
      "x50=[-723.0000010766157,-964.0000007537187]\n",
      "\n",
      "\n",
      "f(x*)=-0.5000000669324542\n"
     ]
    }
   ],
   "source": [
    "# problem 9\n",
    "# NEWTON METHOD\n",
    "# define the augmented lagrangian and its gradient \n",
    "function obj(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    \n",
    "    obj= sin(pi*x1/12) *cos(pi*x2/16) +la*(4*x1-3*x2)+c/2 *(4*x1-3*x2)^2;\n",
    "    return obj\n",
    "end\n",
    "function grd_x(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    grd_x= [pi/12 * cos(pi*x1/12)*cos(pi*x2/16)+4*la+4*c*(4*x1-3*x2), -pi/16 *sin(pi*x1/12)*sin(pi*x2/16)-3*la-3*c*(4*x1-3*x2)];\n",
    "    return grd_x\n",
    "end\n",
    "function hes_x(x0,la, c)\n",
    "    x1=x0[1];\n",
    "    x2=x0[2];\n",
    "    hes_x= [-(pi/12)^2*sin(pi*x1/12)*cos(pi*x2/16)+16*c -pi/16 *pi/12*cos(pi*x1/12)*sin(pi*x2/16)-12*c; -pi/16*pi/12*cos(pi*x1/12)*sin(pi*x2/16)-12*c  -(pi/16)^2*sin(pi*x1/12)*sin(pi*x2/16)+9*c];\n",
    "    \n",
    "    return hes_x\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "function newtmin( obj,grd_x,hes_x, x0,c,la,optTol,alpha,beta; maxit=200)\n",
    "    # Minimize a function the augemented Lagrangian using Newton’s method.\n",
    "    # stop criteria = |grad|< optTol\n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "    f_0 = obj(x0,la,c);\n",
    "    grad_0 = grd_x(x0,la,c);\n",
    "    Hes_0 = hes_x(x0,la,c);\n",
    "    Hes_0 = Hes_0-min(eigmin(Hes_0)-1e-4,0)*eye(length(x0));\n",
    "        \n",
    "    x = x0;\n",
    "    f_x = f_0;\n",
    "    grad_x = grad_0;   \n",
    "    Hes_x = Hes_0;\n",
    "    \n",
    "    #Counts the iteratives.\n",
    "    int = 0;\n",
    "    \n",
    "    while optTol  <= norm(grad_x,2)\n",
    "        \n",
    "        int=int+1;\n",
    "        # if the iteratives number is greater than maxit, break down.\n",
    "        if int >= maxit\n",
    "            break\n",
    "        end\n",
    "        \n",
    "    # applying netwon method\n",
    "    \n",
    "    # determine the direction.\n",
    "    \n",
    "        dx = - inv(Hes_x) *  grad_x ;\n",
    "    \n",
    "        t=1;\n",
    "        bt=0;\n",
    "        at=grad_x' * dx;\n",
    "\n",
    "        while obj(x+t*dx,la,c) >= obj(x,la,c)+alpha*t*at[1]\n",
    "        \n",
    "                t= t * beta;\n",
    "            end # back tracking\n",
    "        \n",
    "        \n",
    "        x=x+dx*t;\n",
    "    \n",
    "        f_x=obj(x,la,c);\n",
    "        grad_x = grd_x(x,la,c);\n",
    "        Hes_x = hes_x(x,la,c);\n",
    "        Hes_x = Hes_x - min(eigmin(Hes_x)-1e-3,0)*eye(length(x0));\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    end # while newton M\n",
    "    \n",
    "    return(x, int) \n",
    "    \n",
    "end   # function\n",
    "\n",
    "\n",
    "beta=0.5;\n",
    "alpha=0.3;\n",
    "x0=[1,2];\n",
    "c=500;\n",
    "lambda=0;\n",
    "opt=1e-3;\n",
    "X=[];\n",
    "x_t=0;\n",
    "count=count+1;\n",
    "while opt >= 1e-7\n",
    "    #newtmin( obj,grd_x,hex_x, x0,c, lambda,optTol     ,c1,c2,beta; maxit=200)\n",
    "    (x, int)= newtmin(obj,grd_x,hes_x,x0,c,lambda,opt ,alpha,beta);\n",
    "    X=push!(X,x);\n",
    "    x0=x;\n",
    "    c=2*c;\n",
    "    opt=opt*0.2;\n",
    "    x_t=x;\n",
    "    count=count+1;\n",
    "    println(\"x\",count,\"=\",x,\"\\n\")\n",
    "end\n",
    "f_min=obj(x_t,0,0);\n",
    "println(\"\\n\",\"f(x*)=\",f_min )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.0",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
